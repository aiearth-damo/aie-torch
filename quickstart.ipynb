{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6a97a0f",
   "metadata": {},
   "source": [
    "# Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8833167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SDK_CLIENT_HOST'] = 'https://pre-engine-aiearth.aliyun.com'\n",
    "import aie\n",
    "\n",
    "aie.Authenticate(\"5a15bf07bb40c4d35c1429b22bb3245a\")\n",
    "aie.g_var.set_var(aie.g_var.GVarKey.Log.LOG_LEVEL, aie.g_var.LogLevel.INFO_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae8c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"./work_dirs/tutorial\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "694720a2",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "## Pre-defined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6632ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requelt sampletset info start\n",
      "https://pre-engine-aiearth.aliyun.com/trainSDK/api/sdk/sampleset/dinfo?id=276\n",
      "requelt sampletset info end\n",
      "root_dir:./work_dirs/tutorial/276/ipwzhdguqhypapsw\n",
      "preprecess start\n",
      "preprecess end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 样本集\n",
    "from aietorch.datasets.aie.aie_dataset import BinaryChangeDetDataset, LandcoverDataset\n",
    "myDataSet = BinaryChangeDetDataset(276, data_root=work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f1c4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requelt sampletset info start\n",
      "https://pre-engine-aiearth.aliyun.com/trainSDK/api/sdk/sampleset/dinfo?id=349\n",
      "requelt sampletset info end\n",
      "root_dir:./work_dirs/tutorial/349/fonnnyvsopwfkrqe\n",
      "preprecess start\n",
      "preprecess end\n"
     ]
    }
   ],
   "source": [
    "landcover = LandcoverDataset(349, data_root=work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c24f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprecess start\n",
      "preprecess end\n"
     ]
    }
   ],
   "source": [
    "# 提取单个类目，其他类目作为背景\n",
    "landcover.set_classes_filter(['industrial_land'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d32b791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background', 'industrial_land']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landcover.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f20a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprecess start\n",
      "preprecess end\n"
     ]
    }
   ],
   "source": [
    "landcover.restore_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbcbfc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['背景',\n",
       " 'industrial_land',\n",
       " 'garden_land',\n",
       " 'urban_residential',\n",
       " 'arbor_forest',\n",
       " 'rural_residential',\n",
       " 'shrub_land',\n",
       " 'traffic_land',\n",
       " 'natural_meadow',\n",
       " 'paddy_field',\n",
       " 'artificial_meadow',\n",
       " 'irrigated_land',\n",
       " 'river',\n",
       " 'dry_cropland',\n",
       " 'lake',\n",
       " 'pond']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landcover.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7325edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aietorch.sampler import RandomNonGeoDatasetSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02cc3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机按照80%， 20%进行切分成两个新样本集\n",
    "train_dataset, val_dataset = RandomNonGeoDatasetSampler.split_by_percent(myDataSet, 0.8)\n",
    "\n",
    "# 随机提取20张图生成新样本集\n",
    "test_dataset = RandomNonGeoDatasetSampler.sample_by_count(myDataSet, 20) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0eb17d5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab75e20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hrnet_w18_base_150k_new512_cosine_lr_batch_48_v25', 'hrnet_w18_base_150k_new512_cosine_lr_batch_48_v25_semi', 'effi-b0_base_50k_new256_cosine_lr_batch_128_adamw', 'hrnet_w18_base_150k_new512_cosine_lr_batch_48_v25_finetune']\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "from aietorch.trainer.mmseg import ChangeDetTrainer\n",
    "\n",
    "print(ChangeDetTrainer.list_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5589f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ChangeDetTrainer(work_dir=work_dir, config_name=\"hrnet_w18_base_150k_new512_cosine_lr_batch_48_v25\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c5fef40",
   "metadata": {},
   "source": [
    "# Customized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9193121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom model\n",
    "from aietorch.models.changedet import ChangedetEncoderDecoder\n",
    "from aietorch.engine.mmseg.models.builder import SEGMENTORS\n",
    "\n",
    "@SEGMENTORS.register_module\n",
    "class MyChangedetEncoder(ChangedetEncoderDecoder):\n",
    "    pass\n",
    "\n",
    "trainer.cfg.model.type = \"MyChangedetEncoder\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7aae3d3b",
   "metadata": {},
   "source": [
    "# Trainer Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea695a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "train\n",
      "val\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "# 设置样本集\n",
    "trainer.setup_dataset(myDataSet)\n",
    "trainer.setup_dataset(train_dataset)\n",
    "trainer.setup_dataset(val_dataset, data_type=\"val\")\n",
    "trainer.setup_dataset(test_dataset, data_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4ba1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练参数\n",
    "trainer.cfg.runner.max_iters = 2\n",
    "trainer.cfg.checkpoint_config.interval = 1\n",
    "#trainer.cfg.optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "#trainer.cfg.optimizer_config = dict(type='Fp16OptimizerHook', loss_scale=512.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b1ad8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maomao/work/tianxun/aie-torch/aietorch/engine/mmseg/models/backbones/hrnet.py:318: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
      "/Users/maomao/work/tianxun/aie-torch/aietorch/engine/mmseg/models/decode_heads/decode_head.py:110: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn('threshold is not defined for binary, and defaults'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 13:30:05,281 - mmseg - INFO - Start running, host: maomao@maomao-workspace.local, work_dir: /Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial\n",
      "2023-03-06 13:30:05,282 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "2023-03-06 13:30:05,283 - mmseg - INFO - workflow: [('train', 1)], max: 2 iters\n",
      "2023-03-06 13:30:05,284 - mmseg - INFO - Checkpoints will be saved to /Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='MyChangedetEncoder',\n",
      "    pretrained='open-mmlab://msra/hrnetv2_w18',\n",
      "    backbone=dict(\n",
      "        type='HRNet',\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        extra=dict(\n",
      "            stage1=dict(\n",
      "                num_modules=1,\n",
      "                num_branches=1,\n",
      "                block='BOTTLENECK',\n",
      "                num_blocks=(4, ),\n",
      "                num_channels=(64, )),\n",
      "            stage2=dict(\n",
      "                num_modules=1,\n",
      "                num_branches=2,\n",
      "                block='BASIC',\n",
      "                num_blocks=(4, 4),\n",
      "                num_channels=(18, 36)),\n",
      "            stage3=dict(\n",
      "                num_modules=4,\n",
      "                num_branches=3,\n",
      "                block='BASIC',\n",
      "                num_blocks=(4, 4, 4),\n",
      "                num_channels=(18, 36, 72)),\n",
      "            stage4=dict(\n",
      "                num_modules=3,\n",
      "                num_branches=4,\n",
      "                block='BASIC',\n",
      "                num_blocks=(4, 4, 4, 4),\n",
      "                num_channels=(18, 36, 72, 144))),\n",
      "        pretrained='open-mmlab://msra/hrnetv2_w18'),\n",
      "    neck=dict(\n",
      "        type='ChangeDetCatBifpn',\n",
      "        in_channels=[18, 36, 72, 144],\n",
      "        num_channels=96),\n",
      "    decode_head=dict(\n",
      "        type='ChangeDetHead',\n",
      "        in_channels=96,\n",
      "        in_index=0,\n",
      "        channels=16,\n",
      "        num_convs=2,\n",
      "        concat_input=True,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=1,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(type='DiceBceLoss')),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole_sigmoid', thresh=0.5, semi_probs=[]))\n",
      "dataset_type = 'ChangeDetDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[127.5, 127.5, 127.5], std=[79.6875, 79.6875, 79.6875], to_rgb=True)\n",
      "crop_size = (896, 896)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadDoubleImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        type='DoubleImageResize',\n",
      "        img_scale=(1024, 1024),\n",
      "        ratio_range=(0.5, 2.0)),\n",
      "    dict(\n",
      "        type='DoubleImageRandomCrop', crop_size=(896, 896), cat_max_ratio=1.0),\n",
      "    dict(type='DoubleImageRandomFog', prob=0.05, size=400, random_color=True),\n",
      "    dict(type='DoubleImageRandomFlip', prob=0.5),\n",
      "    dict(type='DoubleImagePhotoMetricDistortion'),\n",
      "    dict(type='DoubleImageRandomRgbBgr', prob=0.3),\n",
      "    dict(\n",
      "        type='DoubleImageNormalize',\n",
      "        mean=[127.5, 127.5, 127.5],\n",
      "        std=[79.6875, 79.6875, 79.6875],\n",
      "        to_rgb=True),\n",
      "    dict(type='DoubleImageLoadAsBinaryLabel'),\n",
      "    dict(type='DoubleImagePad', size=(896, 896), pad_val=0, seg_pad_val=0),\n",
      "    dict(type='DefaultFormatBundleDoubleImage'),\n",
      "    dict(type='Collect', keys=['img1', 'img2', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadDoubleImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAugCD',\n",
      "        img_scale=None,\n",
      "        img_ratios=[1.0],\n",
      "        transforms=[\n",
      "            dict(type='DoubleImageResize', keep_ratio=True),\n",
      "            dict(\n",
      "                type='DoubleImageNormalize',\n",
      "                mean=[127.5, 127.5, 127.5],\n",
      "                std=[79.6875, 79.6875, 79.6875],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img1', 'img2']),\n",
      "            dict(type='Collect', keys=['img1', 'img2'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=6,\n",
      "    workers_per_gpu=4,\n",
      "    train=[\n",
      "        dict(\n",
      "            type='ChangeDetDataset',\n",
      "            img_dir='',\n",
      "            ann_dir='',\n",
      "            data_root='/',\n",
      "            semi_root=None,\n",
      "            binary_label=True,\n",
      "            split=\n",
      "            '/Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial/train_split_p982xlon.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadDoubleImageFromFile'),\n",
      "                dict(type='LoadAnnotations'),\n",
      "                dict(\n",
      "                    type='DoubleImageResize',\n",
      "                    img_scale=(1024, 1024),\n",
      "                    ratio_range=(0.5, 2.0)),\n",
      "                dict(\n",
      "                    type='DoubleImageRandomCrop',\n",
      "                    crop_size=(896, 896),\n",
      "                    cat_max_ratio=1.0),\n",
      "                dict(\n",
      "                    type='DoubleImageRandomFog',\n",
      "                    prob=0.05,\n",
      "                    size=400,\n",
      "                    random_color=True),\n",
      "                dict(type='DoubleImageRandomFlip', prob=0.5),\n",
      "                dict(type='DoubleImagePhotoMetricDistortion'),\n",
      "                dict(type='DoubleImageRandomRgbBgr', prob=0.3),\n",
      "                dict(\n",
      "                    type='DoubleImageNormalize',\n",
      "                    mean=[127.5, 127.5, 127.5],\n",
      "                    std=[79.6875, 79.6875, 79.6875],\n",
      "                    to_rgb=True),\n",
      "                dict(type='DoubleImageLoadAsBinaryLabel'),\n",
      "                dict(\n",
      "                    type='DoubleImagePad',\n",
      "                    size=(896, 896),\n",
      "                    pad_val=0,\n",
      "                    seg_pad_val=0),\n",
      "                dict(type='DefaultFormatBundleDoubleImage'),\n",
      "                dict(type='Collect', keys=['img1', 'img2', 'gt_semantic_seg'])\n",
      "            ]),\n",
      "        dict(\n",
      "            type='ChangeDetDataset',\n",
      "            img_dir='',\n",
      "            ann_dir='',\n",
      "            data_root='/',\n",
      "            semi_root=None,\n",
      "            binary_label=True,\n",
      "            split=\n",
      "            '/Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial/train_split_y6h0pakd.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadDoubleImageFromFile'),\n",
      "                dict(type='LoadAnnotations'),\n",
      "                dict(\n",
      "                    type='DoubleImageResize',\n",
      "                    img_scale=(1024, 1024),\n",
      "                    ratio_range=(0.5, 2.0)),\n",
      "                dict(\n",
      "                    type='DoubleImageRandomCrop',\n",
      "                    crop_size=(896, 896),\n",
      "                    cat_max_ratio=1.0),\n",
      "                dict(\n",
      "                    type='DoubleImageRandomFog',\n",
      "                    prob=0.05,\n",
      "                    size=400,\n",
      "                    random_color=True),\n",
      "                dict(type='DoubleImageRandomFlip', prob=0.5),\n",
      "                dict(type='DoubleImagePhotoMetricDistortion'),\n",
      "                dict(type='DoubleImageRandomRgbBgr', prob=0.3),\n",
      "                dict(\n",
      "                    type='DoubleImageNormalize',\n",
      "                    mean=[127.5, 127.5, 127.5],\n",
      "                    std=[79.6875, 79.6875, 79.6875],\n",
      "                    to_rgb=True),\n",
      "                dict(type='DoubleImageLoadAsBinaryLabel'),\n",
      "                dict(\n",
      "                    type='DoubleImagePad',\n",
      "                    size=(896, 896),\n",
      "                    pad_val=0,\n",
      "                    seg_pad_val=0),\n",
      "                dict(type='DefaultFormatBundleDoubleImage'),\n",
      "                dict(type='Collect', keys=['img1', 'img2', 'gt_semantic_seg'])\n",
      "            ])\n",
      "    ],\n",
      "    val=[\n",
      "        dict(\n",
      "            type='ChangeDetDataset',\n",
      "            img_dir='',\n",
      "            ann_dir='',\n",
      "            data_root='/',\n",
      "            semi_root=None,\n",
      "            binary_label=True,\n",
      "            split=\n",
      "            '/Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial/val_split_swrt64ni.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadDoubleImageFromFile'),\n",
      "                dict(\n",
      "                    type='MultiScaleFlipAugCD',\n",
      "                    img_scale=None,\n",
      "                    img_ratios=[1.0],\n",
      "                    transforms=[\n",
      "                        dict(type='DoubleImageResize', keep_ratio=True),\n",
      "                        dict(\n",
      "                            type='DoubleImageNormalize',\n",
      "                            mean=[127.5, 127.5, 127.5],\n",
      "                            std=[79.6875, 79.6875, 79.6875],\n",
      "                            to_rgb=True),\n",
      "                        dict(type='ImageToTensor', keys=['img1', 'img2']),\n",
      "                        dict(type='Collect', keys=['img1', 'img2'])\n",
      "                    ])\n",
      "            ])\n",
      "    ],\n",
      "    test=[\n",
      "        dict(\n",
      "            type='ChangeDetDataset',\n",
      "            img_dir='',\n",
      "            ann_dir='',\n",
      "            data_root='/',\n",
      "            semi_root=None,\n",
      "            binary_label=True,\n",
      "            split=\n",
      "            '/Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial/test_split_dxibp0r7.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadDoubleImageFromFile'),\n",
      "                dict(\n",
      "                    type='MultiScaleFlipAugCD',\n",
      "                    img_scale=None,\n",
      "                    img_ratios=[1.0],\n",
      "                    transforms=[\n",
      "                        dict(type='DoubleImageResize', keep_ratio=True),\n",
      "                        dict(\n",
      "                            type='DoubleImageNormalize',\n",
      "                            mean=[127.5, 127.5, 127.5],\n",
      "                            std=[79.6875, 79.6875, 79.6875],\n",
      "                            to_rgb=True),\n",
      "                        dict(type='ImageToTensor', keys=['img1', 'img2']),\n",
      "                        dict(type='Collect', keys=['img1', 'img2'])\n",
      "                    ])\n",
      "            ])\n",
      "    ])\n",
      "log_config = dict(\n",
      "    interval=50,\n",
      "    hooks=[\n",
      "        dict(type='TextLoggerHook', by_epoch=False),\n",
      "        dict(type='TensorboardLoggerHook')\n",
      "    ])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(policy='poly', min_lr=0.0001, by_epoch=False, power=0.9)\n",
      "runner = dict(type='IterBasedRunner', max_iters=2)\n",
      "checkpoint_config = dict(by_epoch=False, interval=1)\n",
      "evaluation = dict(\n",
      "    interval=2000,\n",
      "    metric='mIoU',\n",
      "    save_best='IoU.changedarea',\n",
      "    rule='greater',\n",
      "    pre_eval=True)\n",
      "find_unused_parameters = True\n",
      "work_dir = './work_dirs/tutorial'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cpu'\n",
      "aie_classes = ['background', '变化区域']\n",
      "\n",
      "classes ['background', '变化区域']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "2023-03-06 13:32:09,965 - mmseg - INFO - Saving checkpoint at 1 iterations\n",
      "2023-03-06 13:33:49,570 - mmseg - INFO - Saving checkpoint at 2 iterations\n"
     ]
    }
   ],
   "source": [
    "trainer.train(validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a47ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = os.path.join(work_dir, \"latest.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67aabb45",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15ea5c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./work_dirs/tutorial/latest.pth\n",
      "\"PALETTE\" not found in meta, use dataset.PALETTE instead\n",
      "Config:\n",
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='MyChangedetEncoder',\n",
      "    pretrained=None,\n",
      "    backbone=dict(\n",
      "        type='HRNet',\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        extra=dict(\n",
      "            stage1=dict(\n",
      "                num_modules=1,\n",
      "                num_branches=1,\n",
      "                block='BOTTLENECK',\n",
      "                num_blocks=(4, ),\n",
      "                num_channels=(64, )),\n",
      "            stage2=dict(\n",
      "                num_modules=1,\n",
      "                num_branches=2,\n",
      "                block='BASIC',\n",
      "                num_blocks=(4, 4),\n",
      "                num_channels=(18, 36)),\n",
      "            stage3=dict(\n",
      "                num_modules=4,\n",
      "                num_branches=3,\n",
      "                block='BASIC',\n",
      "                num_blocks=(4, 4, 4),\n",
      "                num_channels=(18, 36, 72)),\n",
      "            stage4=dict(\n",
      "                num_modules=3,\n",
      "                num_branches=4,\n",
      "                block='BASIC',\n",
      "                num_blocks=(4, 4, 4, 4),\n",
      "                num_channels=(18, 36, 72, 144))),\n",
      "        pretrained='open-mmlab://msra/hrnetv2_w18'),\n",
      "    neck=dict(\n",
      "        type='ChangeDetCatBifpn',\n",
      "        in_channels=[18, 36, 72, 144],\n",
      "        num_channels=96),\n",
      "    decode_head=dict(\n",
      "        type='ChangeDetHead',\n",
      "        in_channels=96,\n",
      "        in_index=0,\n",
      "        channels=16,\n",
      "        num_convs=2,\n",
      "        concat_input=True,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=1,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(type='DiceBceLoss')),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(mode='whole_sigmoid', thresh=0.5, semi_probs=[]))\n",
      "dataset_type = 'ChangeDetDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[127.5, 127.5, 127.5], std=[79.6875, 79.6875, 79.6875], to_rgb=True)\n",
      "crop_size = (896, 896)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadDoubleImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        type='DoubleImageResize',\n",
      "        img_scale=(1024, 1024),\n",
      "        ratio_range=(0.5, 2.0)),\n",
      "    dict(\n",
      "        type='DoubleImageRandomCrop', crop_size=(896, 896), cat_max_ratio=1.0),\n",
      "    dict(type='DoubleImageRandomFog', prob=0.05, size=400, random_color=True),\n",
      "    dict(type='DoubleImageRandomFlip', prob=0.5),\n",
      "    dict(type='DoubleImagePhotoMetricDistortion'),\n",
      "    dict(type='DoubleImageRandomRgbBgr', prob=0.3),\n",
      "    dict(\n",
      "        type='DoubleImageNormalize',\n",
      "        mean=[127.5, 127.5, 127.5],\n",
      "        std=[79.6875, 79.6875, 79.6875],\n",
      "        to_rgb=True),\n",
      "    dict(type='DoubleImageLoadAsBinaryLabel'),\n",
      "    dict(type='DoubleImagePad', size=(896, 896), pad_val=0, seg_pad_val=0),\n",
      "    dict(type='DefaultFormatBundleDoubleImage'),\n",
      "    dict(type='Collect', keys=['img1', 'img2', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadDoubleImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAugCD',\n",
      "        img_scale=None,\n",
      "        img_ratios=[1.0],\n",
      "        transforms=[\n",
      "            dict(type='DoubleImageResize', keep_ratio=True),\n",
      "            dict(\n",
      "                type='DoubleImageNormalize',\n",
      "                mean=[127.5, 127.5, 127.5],\n",
      "                std=[79.6875, 79.6875, 79.6875],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img1', 'img2']),\n",
      "            dict(type='Collect', keys=['img1', 'img2'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=6,\n",
      "    workers_per_gpu=4,\n",
      "    train=[\n",
      "        dict(\n",
      "            type='ChangeDetDataset',\n",
      "            img_dir='',\n",
      "            ann_dir='',\n",
      "            data_root='/',\n",
      "            semi_root=None,\n",
      "            binary_label=True,\n",
      "            split=\n",
      "            '/Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial/train_split_p982xlon.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadDoubleImageFromFile'),\n",
      "                dict(type='LoadAnnotations'),\n",
      "                dict(\n",
      "                    type='DoubleImageResize',\n",
      "                    img_scale=(1024, 1024),\n",
      "                    ratio_range=(0.5, 2.0)),\n",
      "                dict(\n",
      "                    type='DoubleImageRandomCrop',\n",
      "                    crop_size=(896, 896),\n",
      "                    cat_max_ratio=1.0),\n",
      "                dict(\n",
      "                    type='DoubleImageRandomFog',\n",
      "                    prob=0.05,\n",
      "                    size=400,\n",
      "                    random_color=True),\n",
      "                dict(type='DoubleImageRandomFlip', prob=0.5),\n",
      "                dict(type='DoubleImagePhotoMetricDistortion'),\n",
      "                dict(type='DoubleImageRandomRgbBgr', prob=0.3),\n",
      "                dict(\n",
      "                    type='DoubleImageNormalize',\n",
      "                    mean=[127.5, 127.5, 127.5],\n",
      "                    std=[79.6875, 79.6875, 79.6875],\n",
      "                    to_rgb=True),\n",
      "                dict(type='DoubleImageLoadAsBinaryLabel'),\n",
      "                dict(\n",
      "                    type='DoubleImagePad',\n",
      "                    size=(896, 896),\n",
      "                    pad_val=0,\n",
      "                    seg_pad_val=0),\n",
      "                dict(type='DefaultFormatBundleDoubleImage'),\n",
      "                dict(type='Collect', keys=['img1', 'img2', 'gt_semantic_seg'])\n",
      "            ]),\n",
      "        dict(\n",
      "            type='ChangeDetDataset',\n",
      "            img_dir='',\n",
      "            ann_dir='',\n",
      "            data_root='/',\n",
      "            semi_root=None,\n",
      "            binary_label=True,\n",
      "            split=\n",
      "            '/Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial/train_split_y6h0pakd.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadDoubleImageFromFile'),\n",
      "                dict(type='LoadAnnotations'),\n",
      "                dict(\n",
      "                    type='DoubleImageResize',\n",
      "                    img_scale=(1024, 1024),\n",
      "                    ratio_range=(0.5, 2.0)),\n",
      "                dict(\n",
      "                    type='DoubleImageRandomCrop',\n",
      "                    crop_size=(896, 896),\n",
      "                    cat_max_ratio=1.0),\n",
      "                dict(\n",
      "                    type='DoubleImageRandomFog',\n",
      "                    prob=0.05,\n",
      "                    size=400,\n",
      "                    random_color=True),\n",
      "                dict(type='DoubleImageRandomFlip', prob=0.5),\n",
      "                dict(type='DoubleImagePhotoMetricDistortion'),\n",
      "                dict(type='DoubleImageRandomRgbBgr', prob=0.3),\n",
      "                dict(\n",
      "                    type='DoubleImageNormalize',\n",
      "                    mean=[127.5, 127.5, 127.5],\n",
      "                    std=[79.6875, 79.6875, 79.6875],\n",
      "                    to_rgb=True),\n",
      "                dict(type='DoubleImageLoadAsBinaryLabel'),\n",
      "                dict(\n",
      "                    type='DoubleImagePad',\n",
      "                    size=(896, 896),\n",
      "                    pad_val=0,\n",
      "                    seg_pad_val=0),\n",
      "                dict(type='DefaultFormatBundleDoubleImage'),\n",
      "                dict(type='Collect', keys=['img1', 'img2', 'gt_semantic_seg'])\n",
      "            ])\n",
      "    ],\n",
      "    val=[\n",
      "        dict(\n",
      "            type='ChangeDetDataset',\n",
      "            img_dir='',\n",
      "            ann_dir='',\n",
      "            data_root='/',\n",
      "            semi_root=None,\n",
      "            binary_label=True,\n",
      "            split=\n",
      "            '/Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial/val_split_swrt64ni.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadDoubleImageFromFile'),\n",
      "                dict(\n",
      "                    type='MultiScaleFlipAugCD',\n",
      "                    img_scale=None,\n",
      "                    img_ratios=[1.0],\n",
      "                    transforms=[\n",
      "                        dict(type='DoubleImageResize', keep_ratio=True),\n",
      "                        dict(\n",
      "                            type='DoubleImageNormalize',\n",
      "                            mean=[127.5, 127.5, 127.5],\n",
      "                            std=[79.6875, 79.6875, 79.6875],\n",
      "                            to_rgb=True),\n",
      "                        dict(type='ImageToTensor', keys=['img1', 'img2']),\n",
      "                        dict(type='Collect', keys=['img1', 'img2'])\n",
      "                    ])\n",
      "            ])\n",
      "    ],\n",
      "    test=[\n",
      "        dict(\n",
      "            type='ChangeDetDataset',\n",
      "            img_dir='',\n",
      "            ann_dir='',\n",
      "            data_root='/',\n",
      "            semi_root=None,\n",
      "            binary_label=True,\n",
      "            split=\n",
      "            '/Users/maomao/work/tianxun/aie-torch/work_dirs/tutorial/test_split_dxibp0r7.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadDoubleImageFromFile'),\n",
      "                dict(\n",
      "                    type='MultiScaleFlipAugCD',\n",
      "                    img_scale=None,\n",
      "                    img_ratios=[1.0],\n",
      "                    transforms=[\n",
      "                        dict(type='DoubleImageResize', keep_ratio=True),\n",
      "                        dict(\n",
      "                            type='DoubleImageNormalize',\n",
      "                            mean=[127.5, 127.5, 127.5],\n",
      "                            std=[79.6875, 79.6875, 79.6875],\n",
      "                            to_rgb=True),\n",
      "                        dict(type='ImageToTensor', keys=['img1', 'img2']),\n",
      "                        dict(type='Collect', keys=['img1', 'img2'])\n",
      "                    ])\n",
      "            ])\n",
      "    ])\n",
      "log_config = dict(\n",
      "    interval=50,\n",
      "    hooks=[\n",
      "        dict(type='TextLoggerHook', by_epoch=False),\n",
      "        dict(type='TensorboardLoggerHook', by_epoch=False)\n",
      "    ])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict(type='OptimizerHook')\n",
      "lr_config = dict(\n",
      "    min_lr=0.0001, by_epoch=False, power=0.9, type='PolyLrUpdaterHook')\n",
      "runner = dict(type='IterBasedRunner', max_iters=2)\n",
      "checkpoint_config = dict(by_epoch=False, interval=1, type='CheckpointHook')\n",
      "evaluation = dict(\n",
      "    interval=2000,\n",
      "    metric='mIoU',\n",
      "    save_best='IoU.changedarea',\n",
      "    rule='greater',\n",
      "    pre_eval=True,\n",
      "    by_epoch=False)\n",
      "find_unused_parameters = True\n",
      "work_dir = './work_dirs/tutorial'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cpu'\n",
      "aie_classes = ['background', '变化区域']\n",
      "\n",
      "[                                                  ] 0/20, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 20/20, 0.7 task/s, elapsed: 27s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "trainer.test(checkpoint, output_dir=\"test_ret\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "312b836c",
   "metadata": {},
   "source": [
    "# Onnx Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c17a922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./work_dirs/tutorial/latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/onnx/symbolic.py:481: UserWarning: \u001b[107m\u001b[1m\u001b[31mDeprecationWarning: This function will be deprecated in future. \u001b[34mWelcome to use the unified model deployment toolbox MMDeploy: https://github.com/open-mmlab/mmdeploy\u001b[0m\n",
      "  warnings.warn(msg)\n",
      "/Users/maomao/work/tianxun/aie-torch/aietorch/models/changedet/segmentors/change_detector.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if return_loss:\n",
      "/Users/maomao/work/tianxun/aie-torch/aietorch/engine/mmseg/ops/wrappers.py:48: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  size = [int(t * self.scale_factor) for t in x.shape[-2:]]\n",
      "/Users/maomao/work/tianxun/aie-torch/aietorch/models/changedet/segmentors/change_detector.py:413: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if flip:\n",
      "/Users/maomao/work/tianxun/aie-torch/venv/lib/python3.9/site-packages/mmcv/onnx/onnx_utils/symbolic_helper.py:30: FutureWarning: 'torch.onnx._patch_torch._node_getitem' is deprecated in version 1.13 and will be removed in version 1.14. Please Internally use '_node_get' in symbolic_helper instead..\n",
      "  tval = value.node()['value']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported ONNX model: ./work_dirs/tutorial/latest.onnx\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add                │ 440            │ \u001b[1;38;5;46m420             \u001b[0m │\n",
      "│ BatchNormalization │ 1              │ 1                │\n",
      "│ Cast               │ 58             │ \u001b[1;38;5;46m0               \u001b[0m │\n",
      "│ Concat             │ 189            │ \u001b[1;38;5;46m5               \u001b[0m │\n",
      "│ Constant           │ 919            │ \u001b[1;38;5;46m0               \u001b[0m │\n",
      "│ Conv               │ 663            │ 663              │\n",
      "│ ConvTranspose      │ 2              │ 2                │\n",
      "│ Div                │ 20             │ \u001b[1;38;5;46m0               \u001b[0m │\n",
      "│ Gather             │ 164            │ \u001b[1;38;5;46m0               \u001b[0m │\n",
      "│ Identity           │ 610            │ \u001b[1;38;5;46m0               \u001b[0m │\n",
      "│ MaxPool            │ 10             │ 10               │\n",
      "│ Mul                │ 48             │ 48               │\n",
      "│ ReduceSum          │ 20             │ \u001b[1;38;5;46m0               \u001b[0m │\n",
      "│ Relu               │ 579            │ \u001b[1;38;5;46m559             \u001b[0m │\n",
      "│ Resize             │ 141            │ 141              │\n",
      "│ Shape              │ 242            │ \u001b[1;38;5;46m0               \u001b[0m │\n",
      "│ Sigmoid            │ 1              │ 1                │\n",
      "│ Slice              │ 126            │ \u001b[1;38;5;46m0               \u001b[0m │\n",
      "│ Unsqueeze          │ 116            │ \u001b[1;38;5;46m0               \u001b[0m │\n",
      "│ Model Size         │ 39.9MiB        │ \u001b[1;38;5;46m39.7MiB         \u001b[0m │\n",
      "└────────────────────┴────────────────┴──────────────────┘\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./work_dirs/tutorial/latest.onnx'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_path = checkpoint.replace(\".pth\", \".onnx\")\n",
    "\n",
    "trainer.export_onnx(output_file=onnx_path, checkpoint_path=checkpoint,shape=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f351e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
